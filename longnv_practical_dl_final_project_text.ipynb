{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "GPU device count: 1\n",
      "Current CUDA device: 0\n",
      "Device name: NVIDIA GeForce RTX 3060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU device count: {torch.cuda.device_count()}\")\n",
    "print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets transformers peft nltk rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from transformers import BartTokenizer\n",
    "\n",
    "\n",
    "def sample_dataset(dataset, fraction=0.3, seed=42):\n",
    "    \"\"\"\n",
    "    Sample a fraction of the dataset.\n",
    "    \"\"\"\n",
    "    sampled_dataset = dataset.shuffle(seed=seed)\n",
    "    num_samples = int(len(dataset) * fraction)\n",
    "    return sampled_dataset.select(range(num_samples))\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples[\"document\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"], max_length=MAX_TARGET_LENGTH, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Create the custom dataset class and data loaders\n",
    "class MultiNewsDataset(Dataset):\n",
    "    def __init__(self, tokenized_datasets, split):\n",
    "        self.dataset = tokenized_datasets[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        return {\n",
    "            'input_ids': torch.tensor(item['input_ids']),\n",
    "            'attention_mask': torch.tensor(item['attention_mask']),\n",
    "            'labels': torch.tensor(item['labels'])\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = pad_sequence([item['attention_mask'] for item in batch], batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence([item['labels'] for item in batch], batch_first=True, padding_value=-100)  # Assuming -100 is ignore index for labels\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "\n",
    "# 1. Load the dataset\n",
    "dataset = load_dataset(\"multi_news\")\n",
    "\n",
    "# 2. Set up the tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "# 3. Preprocess the dataset\n",
    "MAX_INPUT_LENGTH = 1024\n",
    "MAX_TARGET_LENGTH = 100\n",
    "\n",
    "# Sample 10% of each split\n",
    "train_dataset = sample_dataset(dataset['train'])\n",
    "validation_dataset = sample_dataset(dataset['validation'])\n",
    "test_dataset = sample_dataset(dataset['test'])\n",
    "\n",
    "# Create a new dataset dictionary with the sampled splits\n",
    "dataset = {\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset,\n",
    "    'test': test_dataset\n",
    "}\n",
    "\n",
    "\n",
    "tokenized_datasets = {}\n",
    "for split in dataset.keys():\n",
    "    tokenized_datasets[split] = dataset[split].map(preprocess_function, batched=True)\n",
    "\n",
    "train_dataset = MultiNewsDataset(tokenized_datasets, 'train')\n",
    "val_dataset = MultiNewsDataset(tokenized_datasets, 'validation')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer, get_linear_schedule_with_warmup, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base model\n",
    "model_path = r\"D:\\Online_Learning\\Practical_DL\\bart_large_cnn\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_summarizer(model_path, device):\n",
    "    # Load pre-trained model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "    return model, tokenizer\n",
    "\n",
    "def summarize_news(model, tokenizer, news_article):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer([news_article], max_length=2048, return_tensors='pt', truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=100, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "model, tokenizer = load_summarizer(model_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 540,672 || all params: 406,831,104 || trainable%: 0.1329\n"
     ]
    }
   ],
   "source": [
    "# # Define LoRA Config\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "#     r=8,\n",
    "#     lora_alpha=32,\n",
    "#     lora_dropout=0.1,\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"]\n",
    "# )\n",
    "\n",
    "# # Add LoRA adaptor\n",
    "# model_lora = get_peft_model(model, lora_config)\n",
    "# model_lora.print_trainable_parameters()\n",
    "\n",
    "# # Move model to device\n",
    "# model_lora.to(device)\n",
    "\n",
    "# # Set up optimizer and scheduler\n",
    "# optimizer = optim.AdamW(model_lora.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# num_epochs = 7\n",
    "# num_training_steps = num_epochs * len(train_dataloader)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer, \n",
    "#     num_warmup_steps=1,\n",
    "#     num_training_steps=num_training_steps\n",
    "# )\n",
    "\n",
    "target_modules=[]\n",
    "for i in range(0,11):\n",
    "    target_modules += [\n",
    "            f\"model.encoder.layers.{i}.self_attn.k_proj\",\n",
    "            f\"model.encoder.layers.{i}.self_attn.q_proj\",\n",
    "            f\"model.encoder.layers.{i}.self_attn.v_proj\"\n",
    "            ]\n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=target_modules\n",
    ")\n",
    "\n",
    "# Add LoRA adaptor\n",
    "model_lora = get_peft_model(model, lora_config)\n",
    "model_lora.print_trainable_parameters()\n",
    "\n",
    "# Move model to device\n",
    "model_lora.to(device)\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "optimizer = optim.AdamW(model_lora.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 2\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=1,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/3373 [00:00<?, ?it/s]d:\\Programs\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:603: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Epoch 1/2:  12%|‚ñà‚ñè        | 421/3373 [04:56<34:36,  1.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Run the training\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m model_lora \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_lora\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_lora\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Save the fine-tuned model\u001b[39;00m\n\u001b[0;32m     51\u001b[0m model_lora\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model/bart_large_cnn_lora_finetuned_multinews_v3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mtrain_lora\u001b[1;34m(model, train_dataloader, val_dataloader, optimizer, scheduler, num_epochs, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m total_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Set CUDA_LAUNCH_BLOCKING for synchronous CUDA errors\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "def train_lora(model, train_dataloader, val_dataloader, optimizer, scheduler, num_epochs, device):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "        print(f\"Average validation loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Run the training\n",
    "model_lora = train_lora(model_lora, train_dataloader, val_dataloader, optimizer, scheduler, num_epochs, device)\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model_lora.save_pretrained(\"./model/bart_large_cnn_lora_finetuned_multinews_v3\")\n",
    "tokenizer.save_pretrained(\"./model/bart_large_cnn_lora_finetuned_multinews_v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "# Load the LoRA config\n",
    "lora_config = PeftConfig.from_pretrained(\"./model/bart_large_cnn_lora_finetuned_multinews_v2\")\n",
    "\n",
    "# Load the LoRA model\n",
    "lora_model = PeftModel.from_pretrained(base_model, \"./model/bart_large_cnn_lora_finetuned_multinews_v2\")\n",
    "\n",
    "# Merge the LoRA weights with the base model\n",
    "merged_model = lora_model.merge_and_unload()\n",
    "\n",
    "# Save the merged model\n",
    "merged_model.save_pretrained(\"./model/bart_large_cnn_lora_merged_202408\")\n",
    "tokenizer.save_pretrained(\"./model/bart_large_cnn_lora_merged_202408\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Path to your saved merged model\n",
    "merged_model_path = \"./model/bart_large_cnn_lora_merged_202408\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(merged_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_model_path)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to generate summary\n",
    "def generate_summary(model, tokenizer, text, max_length=400, min_length=130):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        # num_beams=4,\n",
    "        # length_penalty=2.0,\n",
    "        # early_stopping=True,\n",
    "        # no_repeat_ngram_size=3,  # Reduce repetition\n",
    "        # do_sample=True,  # Enable sampling\n",
    "        # top_k=50,  # Limit vocabulary for sampling\n",
    "        # top_p=0.95,  # Nucleus sampling\n",
    "    )\n",
    "\n",
    "    # Decode the generated summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Base Model\n",
    "model_path = r\"D:\\Online_Learning\\Practical_DL\\bart_large_cnn\"\n",
    "\n",
    "model_original = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(device)\n",
    "tokenizer_original = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model_original.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 540,672 || all params: 406,831,104 || trainable%: 0.1329\n"
     ]
    }
   ],
   "source": [
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=target_modules  # Targeting only the encoder\n",
    ")\n",
    "\n",
    "\n",
    "# Add LoRA adaptor\n",
    "model_lora = get_peft_model(model_original, lora_config)\n",
    "model_lora.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print out the names of all submodules\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_summarize = '''\n",
    "The widespread anti-immigrant riots in the United Kingdom of the past week, and the false viral claims that fueled them, may be the clearest, most direct example yet of the way unchecked misinformation on social media can produce violence and harm in the real world.\n",
    "\n",
    "Even after authorities identified a UK national as the suspect behind a series of deadly stabbings targeting children, false claims about the attacker‚Äôs name and origins continued to stoke anti-immigrant fervor and propel far-right demonstrations.\n",
    "\n",
    "The fake claims have circulated widely, particularly on X, the platform formerly known as Twitter, extremism researchers said. And police have openly blamed that misinformation for the violence that has wracked the country in recent days, with rioters throwing bricks at mosques, setting cars on fire and chanting anti-Islamic slogans while clashing with officers in riot gear.\n",
    "\n",
    "The events of the past week are hardly the only example of the link between online misinformation and politically motivated violence: From the Rohingya genocide to the attack on the US Capitol on January 6, 2021, false and misleading claims have consistently been at the center of high-profile incidences of political unrest and violence.\n",
    "\n",
    "It is a pattern that keeps repeating despite years of calls by governments and civil society groups for social media platforms to rein in inflammatory, hateful posts, as well as pledges by companies themselves to do more.\n",
    "\n",
    "A recent retreat from content moderation by some major platforms, however, suggests that the problem of violence fueled by misinformation may well get worse before it gets better.\n",
    "\n",
    "For nearly a decade, governments and civil rights groups have increasingly argued that online platforms have created enormous societal costs.\n",
    "\n",
    "Critics of social media have repeatedly accused the industry of putting corporate profits before users‚Äô mental health, or opening the door to foreign meddling, without doing enough to shield the world from those risks.\n",
    "\n",
    "An economist might call these negative externalities ‚Äì like pollution, they are byproducts of a profit-seeking business that, left unaddressed, everyone else must either learn to live with or mitigate, usually at great collective expense. The consequences tend to play out over long timeframes and with large-scale, systemic effects.\n",
    "\n",
    "Police hold back rioters near a burning police vehicle after disorder broke out on July 30, 2024, in Southport, England.\n",
    "Related article\n",
    "Elon Musk says ‚Äòcivil war is inevitable‚Äô as UK rocked by far-right riots. He‚Äôs part of the problem\n",
    "This week, it is hard to avoid wondering whether politically motivated violence based on nothing more than bad-faith, evidence-free speculation has become a permanent fixture among social media‚Äôs various externalities, and if we are being asked to make peace with it as a condition of living in a digitally connected world.\n",
    "\n",
    "Many social media companies have invested heavily in content moderation over the years. But the industry‚Äôs recent track record hints at a bet ‚Äì or perhaps a hope ‚Äì that just maybe, the public will tolerate a bit more pollution.\n",
    "\n",
    "There are some signs of pushback. In the European Union, officials are looking to hold social media companies accountable for spreading misinformation under the new Digital Services Act. In the UK, the Online Safety Act could take effect as soon as this year, requiring, among other things, social media platforms to remove illegal content.\n",
    "\n",
    "And even tougher rules may be on the way as a result of the riots. ‚ÄúWe‚Äôre going to have to look more broadly at social media after this disorder,‚Äù UK Prime Minister Keir Starmer said in a video distributed to media Friday.\n",
    "\n",
    "But punishments for online wrongdoing are already being handed out to individual perpetrators. On Friday, Jordan Parlour from Leeds, England, was sentenced to 20 months in jail after being convicted of publishing written material intended to stir racial hatred. The 28-year-old had posted the material on Facebook.\n",
    "\n",
    "The United States has lagged on platform regulation, partly due to congressional dysfunction and partly because of legal and constitutional differences that grant online platforms more freedom to manage their own websites.\n",
    "\n",
    "Still, lawmakers made some moves last month when the US Senate passed the Kids Online Safety Act, which aims to combat mental health harms for teens linked to social media.\n",
    "\n",
    "It may be tempting to dismiss social media‚Äôs role in the UK riots as merely a reflection of latent political trends or the result of activism that would have happened on other platforms anyway.\n",
    "\n",
    "But that distracts from the calculation that some platforms appear to have made: At least some of the time, some amount of misinformation-fueled violence is a reasonable cost for society to pay.\n",
    "\n",
    "Olesya Dmitracova and Kara Fox contributed reporting.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:603: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "False and misleading claims have consistently been at the center of high-profile incidences of political unrest and violence. It is a pattern that keeps repeating despite years of calls by governments and civil society groups for social media platforms to rein in inflammatory, hateful posts. A recent retreat from content moderation by some major platforms suggests that the problem of violence fueled by misinformation may well get worse before it gets better. ‚ÄúWe‚Äôre going to have to look more broadly at social media after this disorder,‚Äù UK Prime Minister Keir Starmer said in a video distributed to media Friday. But punishments for online wrongdoing are already being handed out to individual perpetrators. On Friday, Jordan Parlour was sentenced to 20 months in jail after being convicted of publishing written material intended to stir racial hatred.\n"
     ]
    }
   ],
   "source": [
    "summary = generate_summary(model_original, tokenizer_original, text_to_summarize)\n",
    "print(\"Generated Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "‚Äì The UK riots of the past week may be the clearest, most direct example yet of the way unchecked misinformation on social media can produce violence and harm in the real world, the Guardian reports. Even after authorities identified a UK national as the suspect behind a series of deadly stabbings targeting children, false claims about the attacker's name and origins continued to stoke anti-immigrant fervor and propel far-right demonstrations. The fake claims have circulated widely, particularly on X, the platform formerly known as Twitter, extremism researchers say. And police have openly blamed that misinformation for the violence that has wracked the country in recent days, with rioters\n"
     ]
    }
   ],
   "source": [
    "## Merge model\n",
    "summary = generate_summary(model, tokenizer_original, text_to_summarize)\n",
    "print(\"Generated Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "test_dataset = sample_dataset(dataset['test'])\n",
    "test_dataset_tokenized = MultiNewsDataset(tokenized_datasets, 'test')\n",
    "\n",
    "generated_summaries = [generate_summary(model, tokenizer_original, doc) for doc in test_dataset['document']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \n",
    "generated_summaries_original = [generate_summary(model_original, tokenizer_original, doc) for doc in test_dataset['document']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_32284\\1842060126.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric('rouge',trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with ROUGE\n",
    "rouge = load_metric('rouge',trust_remote_code=True)\n",
    "\n",
    "references = test_dataset['summary']\n",
    "result_1 = rouge.compute(predictions=generated_summaries, references=references)\n",
    "result_2 = rouge.compute(predictions=generated_summaries_original, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_text = pd.read_csv('./practical_dl_final_project/scraped_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_result = []\n",
    "summary_result_cnn = []\n",
    "for item in df_text[df_text['url'].str.contains('cnn')]['txt']:\n",
    "    summary_result.append(generate_summary(model, tokenizer_original, item))\n",
    "    summary_result_cnn.append(generate_summary(model_original, tokenizer_original, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnn = df_text[df_text['url'].str.contains('cnn')]['txt'].copy()\n",
    "df_cnn['summary_lora'] = summary_result\n",
    "df_cnn['summary_cnn'] = summary_result_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Äì A major ad industry group is shutting down, days after Elon Musk-owned X filed a lawsuit claiming the group illegally conspired to boycott advertising on his platform. The group, Global Alliance for Responsible Media, also known as GARM, is a voluntary ad-industry initiative run by the World Federation of Advertisers that aims to help brands avoid having their advertisements appear alongside illegal or harmful content. ‚ÄúGARM is a small, not-for-profit initiative, and recent allegations that unfortunately misconstrue its purpose and activities have caused a distraction and significantly drained its resources and finances,‚Äù the group said in a statement Friday.\n",
      "The group, Global Alliance for Responsible Media, also known as GARM, is a voluntary ad-industry initiative run by the World Federation of Advertisers. The end of GARM marks a temporary victory for Elon Musk and X CEO Linda Yaccarino, even though a judge hasn‚Äôt made a ruling yet. The lawsuit could drive away even more advertisers from X, Nandini Jammi and Claire Atkin, founders of watchdog group Check My Ads Institutewrote in an op-ed Thursday. X alsosued the progressive watchdog groupMedia Matters over itsanalysishighlighting antisemitic and pro-Nazi content on X.\n"
     ]
    }
   ],
   "source": [
    "print(summary_result[2])\n",
    "print(summary_result_cnn[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚Äì If reelected, Donald Trump said Thursday, he\\'d try to exert direct power over monetary policy. \"I feel the president should have at least a say in there. I feel that strongly,‚Äù Trump said toward the end of hispress conference. ‚ÄúI made a lot of money. I was very successful. And I think I have a better instinct than, in many cases, people that would be on the Federal Reserve ‚Äî or the chairman.‚Äù The former president said that Fed Chair Jerome Powell, whom Trump appointed to the position in 2017, has got the timing of rate moves wrong throughout his tenure.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Donald Trump said Thursday he'd try to exert direct power over monetary policy if reelected. The former president said that Fed Chair Jerome Powell has got the timing of rate moves wrong throughout his tenure. Trump has publicly feuded with Powell for years, frequently posting on social media that he disagreed with the Fed‚Äôs decision to raise rates in Powell's pre-Covid rate-hiking campaign. The Fed is designed to be an independent governing body, free from political influence, so that it cannot be bullied into making emotional decisions that could upset the delicate balance of job creation and low inflation. It takes time for rate hikes or cuts to take effect in the economy, so timing a policy decision right is a tricky game.\",\n",
       " \"CrowdStrike and Microsoft have claimed Delta‚Äôs outage lasted substantially longer than its rivals‚Äô service downtime. CrowdStrike said Delta was responsible for thousands of cancellations that piled up over the course of a week. Delta canceled 7,000 flights between July 19 and July 24 as a result of the outage. Delta customers this week have fileda class-action lawsuit, alleging that Delta refused to refundsto them with mass cancellations. The US Department of Transportation is investigating those claims and is investigating CrowdStrike and Delta's claim that Delta ignored its help to restore its systems. The battle between Delta and the tech companies kicked off late last month when Delta CEO Ed Bastian saidin an interview on CNBC that CrowdStrike was willfully negligent in its post-crash conduct.\",\n",
       " 'The group, Global Alliance for Responsible Media, also known as GARM, is a voluntary ad-industry initiative run by the World Federation of Advertisers. The end of GARM marks a temporary victory for Elon Musk and X CEO Linda Yaccarino, even though a judge hasn‚Äôt made a ruling yet. The lawsuit could drive away even more advertisers from X, Nandini Jammi and Claire Atkin, founders of watchdog group Check My Ads Institutewrote in an op-ed Thursday. X alsosued the progressive watchdog groupMedia Matters over itsanalysishighlighting antisemitic and pro-Nazi content on X.',\n",
       " \"ChatGPT‚Äôs advanced voice mode sounds remarkably lifelike. It responds in real time, can adjust to being interrupted, makes the kinds of noises that humans make during conversations like laughing or ‚Äúhmms‚Äù OpenAI says it observed users talking to ChatGPT's voice mode in language ‚Äúexpressing shared bonds‚Äù with the tool. Eventually, ‚Äúusers might form social relationships with the AI, reducing their need for human interaction ‚Äî potentially benefiting lonely individuals but possibly affecting healthy relationships,‚Äù the company said in a report. It adds that hearing information from a bot that sounds like a human could lead users to trust the tool more than they should, given AI's propensity to get things wrong.\",\n",
       " 'Paramount Global, the storied media conglomerate, announced Thursday it will lay off 15% of its US staff and write down $6 billion in value of its cable television networks. The layoffs, which will affect around 2,000 staffers in the coming weeks, are part of Paramount‚Äôs bid to trim $500 million in annual costs companywide. The announcement is the latest painful sign of the dramatic changes impacting the traditional television business as consumers rapidly shift away from the cable bundle in favor of streaming services. On Wednesday, Warner Bros. Discovery, the parent company of CNN, TNT, HGTV and other cable networks, posted a$9.1 billion write downon its television business.',\n",
       " 'Many big-box retailers are getting into spooky season earlier than ever before. Popularized by the Disney TV show ‚ÄúGravity Falls,‚Äô TikTok users are showcasing their Summerween parties with watermelon-carved jack-o‚Äô-lanterns. Starbucks released its beloved (or hated, depending on the point of view)pumpkin spice latteon Thursday, the earliest it has ever started selling the seasonal beverage. It underscores how even though consumers may want to cut back on spending, ‚Äúin the actual moment, such as when Halloween products are marketing early, they may actually splurge instead,‚Äù Kelsey Robinson, a senior partner at McKinsey said.',\n",
       " \"US economy is still growing at an annualized rate close to 3% in the most recent quarter. While any pullback in spending can be a worrying sign for the US economy, it's important to zoom out before you freak out. The travel industry is also seeing demand soften, but it‚Äôs softening relative to the huge boost it got in the months after Covid restrictions were lifted. ‚ÄúYou need a PhD plan to Disney World anymore ‚Äî they‚Äôve made it so complicated,‚Äù Pete Werner, who runs Dreams Unlimited Travel, told me last year. The high-income consumer is feeling a little bit of stress internationally, he said.\",\n",
       " 'A letter criticizes nearly a dozen tech firms for their lack of participation in two programs that make it easier for people to request the removal of non-consensual explicit images and videos from the internet. This year alone, women around the world were targeted by AI-generated pornographic images, ranging from popstar Taylor Swift tohigh school girls. Most of the companies named in the letter have policies against the creation or sharing of such images, and in some cases offer their own ways for users to report or remove such content. But the benefit of joining the group is that users need to submit only one removal request that is directed to all the participating platforms, rather than contacting each individual company one-by-one.',\n",
       " 'False and misleading claims have consistently been at the center of high-profile incidences of political unrest and violence. It is a pattern that keeps repeating despite years of calls by governments and civil society groups for social media platforms to rein in inflammatory, hateful posts. A recent retreatfrom content moderation by some major platforms suggests that the problem of violence fueled by misinformation may well get worse before it gets better. It may be tempting to dismiss social media‚Äôs role in the UK riots as merely a reflection of latent political trends or the result of activism that would have happened on other platforms. But that distracts from the calculation that some platforms appear to have made: At least some of the time, some amount of misinformation-fueled violence is a reasonable cost for society to pay.',\n",
       " \"The Japanese Nikkei 225 index tanked more than 12% on Monday, marking its worst performance since 1987. The S&P 500 sank more than 3% and shed $1.3 trillion in value, notching its worst day since the 2022 bear market. The VIX, known as Wall Street‚Äôs fear gauge, shot up to a four-year high. Despite the brutal week, stocks are still on pace to notch strong returns for the year: The Dow is up 11.5% for 2024, and the Nasdaq has climbed 11.7% for the same period.. Some investors say there could be more volatility to come, particularly since it's unclear how much more the yen carry trade could unwind.\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_result_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1+cu118'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Markets Hot Stocks Fear & Greed Index Latest Market News Hot Stocks Paramount Global, the storied media conglomerate, announced Thursday it will lay off 15% of its US staff and write down $6 billion in value of its cable television networks as it prepares to merge with Skydance Media. The layoffs, which will affect around 2,000 staffers in the coming weeks, are part of Paramount‚Äôs bid to trim $500 million in annual costs companywide aheadof its mergerwith technology scion David Ellison‚Äôs SkyDance. The layoffs will see the elimination of ‚Äúredundant functions‚Äù in marketing and communications and the reduction of headcount in finance, legal, technology, and other support functions, Paramount co-chief executive Chris McCarthy said. Paramount, which controls a vast cable and television portfolio, said the writedown of its TV business ‚Äúis primarily as a result of recent indicators in the linear affiliate marketplace, and the estimated total company market value indicated by the Skydance transactions.‚Äù The announcement is the latest painful sign of the dramatic changes impacting the traditional television business as consumers rapidly shift away from the cable bundle in favor of streaming services. On Wednesday, Warner Bros. Discovery, the parent company of CNN, TNT, HGTV and other cable networks, posted a$9.1 billion write downon its television business. Related articleWarner Bros. Discovery signals rapid deterioration of television business, sending stock plummeting ‚ÄúIt‚Äôs fair to say that even two years ago, market valuations and prevailing conditions for legacy media companies were quite different than they are today,‚Äù WBD chief executive David Zaslav said on a call with investors. ‚ÄúAnd this impairment acknowledges this.‚Äù The recent turbulence in the media business extends well beyond the traditional television industry, affecting digital news outlets and print publications. In recent days, Axios announced it would lay off 10% of its staff, or around 50 employees, making the first time the news outlet has conducted layoffs in its history, amid what it described as ‚Äúchanges in the media business.‚Äù ‚ÄúThis is a painful but necessary move to tighten our strategic focus and shift investment to our core growth areas. We‚Äôre making some difficult changes to adapt fast to a rapidly changing media landscape,‚Äù Axios chief executive Jim VandeHei wrote in a memo to staff obtained by CNN, calling it ‚Äúthe most difficult moment for media in our lifetime.‚Äù Related articleDisney may have a parks problem Also this week, the venerable TV trade magazine Broadcasting+Cable, which was founded in 1931, announced it would shutter over what its parent company described as a ‚Äúrapid transformation‚Äù of the industry. As profits in the television business have eroded away, Paramount has been hit particularly hard. The iconic company, which owns a slate of cable networks including Nickelodeon, Comedy Central and MTV, has seen its valuation plunge amid the turmoil, with shares of Paramount falling nearly 80% in the last five years. Still, there have been a few bright spots in recent days. Paramount said its streaming service Paramount+ posted a $26 million profit after losing $424 million during the same period last year and said it expects subscriber growth in the second half of the year. Warner Bros. Discovery reported its HBO, Max and Discovery+ streaming services added 3.6 million new subscribers in the latest quarter as it continues to expand around the world, for a total of 103.3 million global subscribers. Most stock quote data provided by BATS. US market indices are shown in real time, except for the S&P 500 which is refreshed every two minutes. All times are ET. Factset: FactSet Research Systems Inc. All rights reserved. Chicago Mercantile: Certain market data is the property of Chicago Mercantile Exchange Inc. and its licensors. All rights reserved. Dow Jones: The Dow Jones branded indices are proprietary to and are calculated, distributed and marketed by DJI Opco, a subsidiary of S&P Dow Jones Indices LLC and have been licensed for use to S&P Opco, LLC and CNN. Standard & Poor‚Äôs and S&P are registered trademarks of Standard & Poor‚Äôs Financial Services LLC and Dow Jones is a registered trademark of Dow Jones Trademark Holdings LLC. All content of the Dow Jones branded indices Copyright S&P Dow Jones Indices LLC and/or its affiliates. Fair value provided by IndexArb.com. Market holidays and trading hours provided by Copp Clark Limited. ¬© 2024 Cable News Network. A Warner Bros. Discovery Company. All Rights Reserved.CNN Sans ‚Ñ¢ & ¬© 2016 Cable News Network.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text[df_text['url'].str.contains('cnn')]['txt'].values[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_modules of BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
